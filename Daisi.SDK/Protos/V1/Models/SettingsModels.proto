syntax = "proto3";

import "Protos/V1/Models/PeerModels.proto";
import "Protos/V1/Models/InferenceModels.proto";
import "Protos/V1/Models/HostModels.proto";
import "google/protobuf/wrappers.proto";

package daisi.protos.v1;


message GetAllSettingsRequest {
    optional google.protobuf.StringValue SessionId = 1;

}
message GetAllSettingsResponse{
    Settings Settings = 1;
}
message Settings {
    PeerSettings Peer = 1;
    HostSettings Host = 2;
    ModelSettings Model = 3;
    StorageSettings Storage = 4;
    DriveSettings Drive = 5;
}

message SetAllSettingsRequest{
    optional google.protobuf.StringValue SessionId = 1;
    Settings Settings = 2;
}
message SetAllSettingsResponse{
    bool Success = 1;
}

message PeerSettings{
    repeated Peer Peers = 1;
    int32 DiscoveryPort = 2;
    int32 MaxPeers = 3;
}
message ModelSettings{
    string ModelFolderPath = 1;
    repeated AIModel Models = 2;
    bool AutomaticDownloads = 3;
    reserved 4; // was Backend (global BackendSettings)
    string VoiceModelFolderPath = 6;
    string TranscriptionModelPath = 7;
    bool EnableTTS = 8;
    bool EnableSTT = 9;
    string DefaultVoiceId = 10;
    BackendRuntimes Runtime = 11;
    bool ShowLogs = 12;
    bool AutoFallback = 13;
    bool SkipCheck = 14;
    string LlamaPath = 15;
    string LlavaPath = 16;
}
message HostSettings {
    string Id = 1;
    string Name = 2;
    int32 MaxConcurrentSessions = 3;
    string SecretKey = 4;
    google.protobuf.StringValue OrcIpAddressOrDomain = 5;
    google.protobuf.Int32Value OrcPort = 6;
    bool AutoUpdate = 7;
    string LogLevel = 8;
    bool OrcUseSSL = 9;
    bool ToolsOnly = 10;

}
message BackendSettings {
    BackendRuntimes Runtime = 1;
    bool ShowLogs = 2;
    bool AutoFallback = 3;
    bool SkipCheck = 4;
    string LlamaPath = 5;
    string LlavaPath = 6;
    uint32 ContextSize = 7;
    int32 GpuLayerCount = 8;
    uint32 BatchSize = 9;
    string BackendEngine = 10;
    optional float Temperature = 11;
    optional float TopP = 12;
    optional int32 TopK = 13;
    optional float RepeatPenalty = 14;
    optional float PresencePenalty = 15;
    string PromptFormat = 16;
}
enum BackendRuntimes {
    Auto = 0;
    Cuda = 1;
    Vulkan = 2;
    Avx = 3;
    Avx2 = 4;
    Avx512 = 5;
}
enum AIModelTypes {
    TextGeneration = 0;
    ImageGeneration = 1;
    AudioGeneration = 2;
    VideoGeneration = 3;
    SpeechToText = 4;
    TextToSpeech = 5;
    CodeGeneration = 6;
}
message AIModel {
    string Name = 1;
    string FileName = 2;
    string Url = 3;
    bool IsMultiModal = 4;
    bool IsDefault = 5;
    bool Enabled = 6;
    bool LoadAtStartup = 7;
    repeated ThinkLevels ThinkLevels = 8;
    bool HasReasoning = 9;
    optional BackendSettings Backend = 10;
    string Id = 11;
    AIModelTypes Type = 12;
    repeated AIModelTypes Types = 13;
}
message StorageSettings{
    StorageLocations Location = 1;
    string LocalPath = 2;
}
enum StorageLocations{
    None = 0;
    Local = 1;
    Cloud = 2;
}